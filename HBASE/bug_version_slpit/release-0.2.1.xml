<?xml version="1.0" encoding="utf-8"?>
<bugrepository name="HBASE">
	<bug fixdate="2008-08-12 22:12:10" id="824" opendate="2008-08-12 21:49:40" resolution="Fixed">
		
		
		<buginformation>
			
			
			<summary>Bug in Hlog we print array of byes for region name</summary>
			
			
			<description>I see lines in the debug logs like this

2008-08-12 16:13:20,638 DEBUG org.apache.hadoop.hbase.regionserver.HLog: Found 1 logs to remove using oldest outstanding seqnum of 265156192 from region [B@18a3257

</description>
			
			
			<version>0.2.1</version>
			
			
			<fixedVersion>0.2.1, 0.18.0</fixedVersion>
			
			
			<type>Bug</type>
			
		
		</buginformation>
		
		
		<fixedFiles>
			
			
			<file type="M">org.apache.hadoop.hbase.regionserver.HLog.java</file>
			
		
		</fixedFiles>
		
	
	</bug>
	<bug fixdate="2008-08-13 00:21:34" id="825" opendate="2008-08-12 23:36:03" resolution="Fixed">
		
		
		<buginformation>
			
			
			<summary>master logs showing byte[] in place of string on logging</summary>
			
			
			<description>
2008-08-12 17:39:48,586 INFO org.apache.hadoop.hbase.master.RegionManager: Skipping region [B@6a63d3 because it is already closing.

</description>
			
			
			<version>0.2.1</version>
			
			
			<fixedVersion>0.2.1, 0.18.0</fixedVersion>
			
			
			<type>Bug</type>
			
		
		</buginformation>
		
		
		<fixedFiles>
			
			
			<file type="M">org.apache.hadoop.hbase.master.RegionManager.java</file>
			
		
		</fixedFiles>
		
	
	</bug>
	<bug fixdate="2008-08-25 19:19:21" id="843" opendate="2008-08-25 18:44:31" resolution="Fixed">
		
		
		<buginformation>
			
			
			<summary>Deleting and recreating a table in a single process does not work</summary>
			
			
			<description>When you delete and then recreate/enable the same table in the same process, when you get the HTable reference to the new table you are actually given the old table.
The connection information is never deleted/invalidated.
To fix, we add a call to HConnectionManager.deleteConnectionInfo(conf) at the end of HBaseAdmin.deleteTable().  This information will then be re-loaded with the latest table references once the client asks for it.</description>
			
			
			<version>0.2.1</version>
			
			
			<fixedVersion>0.2.1, 0.18.0</fixedVersion>
			
			
			<type>Bug</type>
			
		
		</buginformation>
		
		
		<fixedFiles>
			
			
			<file type="M">org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
			
		
		</fixedFiles>
		
	
	</bug>
	<bug fixdate="2008-08-31 04:21:08" id="855" opendate="2008-08-29 07:45:35" resolution="Fixed">
		
		
		<buginformation>
			
			
			<summary>compaction can return less versions then we should in some cases</summary>
			
			
			<description>say we have a column with max version = 3 and we have 3 records  
we insert a new record with a old timestamp.
What happeds in the compaction is the the new record with the old timestamp get read first and could push out some of our 
versions if the new record(s) with the old timestamp has a expired ttl.
This happens because we track the total times we see a row/column but do not reduce this count if the cell is expired
and sense we pass the cell in order of the newest HStoreFile first with the newest records passed might not be the newest timestamps.
Got to wait for HBASE-834 to be committed then I can add a patch for this bug. will be a simple fix.</description>
			
			
			<version>0.2.1</version>
			
			
			<fixedVersion>0.2.1, 0.18.0</fixedVersion>
			
			
			<type>Bug</type>
			
		
		</buginformation>
		
		
		<fixedFiles>
			
			
			<file type="M">org.apache.hadoop.hbase.regionserver.HStore.java</file>
			
			
			<file type="M">org.apache.hadoop.hbase.regionserver.TestCompaction.java</file>
			
			
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
			
		
		</fixedFiles>
		
	
	</bug>
	<bug fixdate="2008-09-05 23:57:53" id="872" opendate="2008-09-05 15:50:29" resolution="Fixed">
		
		
		<buginformation>
			
			
			<summary>Getting exceptions in shell when creating/disabling tables</summary>
			
			
			<description>On the list from Dru Jensen:
I am testing the release candidate with hadoop 0.17.2.1 release.  I am curious if others are seeing this or if I have something mis-configured.
I reformatted the dfs and recreated everything from scratch.
hbase(main):009:0&amp;gt; version
Version: 0.2.1, r691710, Wed Sep  3 11:50:24 PDT 2008
I occasionally get the following error performing a create table.  However when I do a list, the table was successfully created.
hbase(main):007:0&amp;gt; create &amp;amp;apos;test&amp;amp;apos;, &amp;amp;apos;avg&amp;amp;apos;, &amp;amp;apos;std&amp;amp;apos;, &amp;amp;apos;max&amp;amp;apos;
NativeException: org.apache.hadoop.hbase.client.NoServerForRegionException: No server address listed in .META. for region test,,1220628716239
       from org/apache/hadoop/hbase/client/HConnectionManager.java:536:in `locateRegionInMeta&amp;amp;apos;
       from org/apache/hadoop/hbase/client/HConnectionManager.java:459:in `locateRegion&amp;amp;apos;
       from org/apache/hadoop/hbase/client/HConnectionManager.java:419:in `locateRegion&amp;amp;apos;
       from org/apache/hadoop/hbase/client/HBaseAdmin.java:157:in `createTable&amp;amp;apos;
       from sun/reflect/NativeMethodAccessorImpl.java:-2:in `invoke0&amp;amp;apos;
       from sun/reflect/NativeMethodAccessorImpl.java:39:in `invoke&amp;amp;apos;
       from sun/reflect/DelegatingMethodAccessorImpl.java:25:in `invoke&amp;amp;apos;
       from java/lang/reflect/Method.java:585:in `invoke&amp;amp;apos;
       from org/jruby/javasupport/JavaMethod.java:250:in `invokeWithExceptionHandling&amp;amp;apos;
       from org/jruby/javasupport/JavaMethod.java:219:in `invoke&amp;amp;apos;
       from org/jruby/javasupport/JavaClass.java:416:in `execute&amp;amp;apos;
       from org/jruby/internal/runtime/methods/SimpleCallbackMethod.java:67:in `call&amp;amp;apos;
       from org/jruby/internal/runtime/methods/DynamicMethod.java:78:in `call&amp;amp;apos;
       from org/jruby/runtime/CallSite.java:329:in `call&amp;amp;apos;
       from org/jruby/evaluator/ASTInterpreter.java:649:in `callNode&amp;amp;apos;
       from org/jruby/evaluator/ASTInterpreter.java:324:in `evalInternal&amp;amp;apos;
... 121 levels...
       from ruby.opt.hbase_minus_0_dot_2_dot_1.bin.hirbInvokermethod__23$RUBY$startOpt:-1:in `call&amp;amp;apos;
       from org/jruby/internal/runtime/methods/DynamicMethod.java:74:in `call&amp;amp;apos;
       from org/jruby/internal/runtime/methods/CompiledMethod.java:48:in `call&amp;amp;apos;
       from org/jruby/runtime/CallSite.java:123:in `cacheAndCall&amp;amp;apos;
       from org/jruby/runtime/CallSite.java:298:in `call&amp;amp;apos;
       from ruby/opt/hbase_minus_0_dot_2_dot_1/bin//opt/hbase/bin/../bin/hirb.rb:351:in `_file_&amp;amp;apos;
       from ruby/opt/hbase_minus_0_dot_2_dot_1/bin//opt/hbase/bin/../bin/hirb.rb:-1:in `_file_&amp;amp;apos;
       from ruby/opt/hbase_minus_0_dot_2_dot_1/bin//opt/hbase/bin/../bin/hirb.rb:-1:in `load&amp;amp;apos;
       from org/jruby/Ruby.java:512:in `runScript&amp;amp;apos;
       from org/jruby/Ruby.java:432:in `runNormally&amp;amp;apos;
       from org/jruby/Ruby.java:312:in `runFromMain&amp;amp;apos;
       from org/jruby/Main.java:144:in `run&amp;amp;apos;
       from org/jruby/Main.java:89:in `run&amp;amp;apos;
       from org/jruby/Main.java:80:in `main&amp;amp;apos;
       from /opt/hbase/bin/../bin/hirb.rb:228:in `create&amp;amp;apos;
       from (hbase):8:in `binding&amp;amp;apos;hbase(main):008:0&amp;gt;
And occasionally, I get this exception when trying to disable a table. However it was successfully disabled.
hbase(main):002:0&amp;gt; disable &amp;amp;apos;test&amp;amp;apos;
NativeException: java.io.IOException: unable to disable table test
       from org/apache/hadoop/hbase/client/HBaseAdmin.java:418:in `disableTable&amp;amp;apos;
       from org/apache/hadoop/hbase/client/HBaseAdmin.java:379:in `disableTable&amp;amp;apos;
       from sun/reflect/NativeMethodAccessorImpl.java:-2:in `invoke0&amp;amp;apos;
       from sun/reflect/NativeMethodAccessorImpl.java:39:in `invoke&amp;amp;apos;
       from sun/reflect/DelegatingMethodAccessorImpl.java:25:in `invoke&amp;amp;apos;
       from java/lang/reflect/Method.java:585:in `invoke&amp;amp;apos;
       from org/jruby/javasupport/JavaMethod.java:250:in `invokeWithExceptionHandling&amp;amp;apos;
       from org/jruby/javasupport/JavaMethod.java:219:in `invoke&amp;amp;apos;
       from org/jruby/javasupport/JavaClass.java:416:in `execute&amp;amp;apos;
       from org/jruby/internal/runtime/methods/SimpleCallbackMethod.java:67:in `call&amp;amp;apos;
       from org/jruby/internal/runtime/methods/DynamicMethod.java:78:in `call&amp;amp;apos;
       from org/jruby/runtime/CallSite.java:155:in `cacheAndCall&amp;amp;apos;
       from org/jruby/runtime/CallSite.java:332:in `call&amp;amp;apos;
       from org/jruby/evaluator/ASTInterpreter.java:649:in `callNode&amp;amp;apos;
       from org/jruby/evaluator/ASTInterpreter.java:324:in `evalInternal&amp;amp;apos;
       from org/jruby/evaluator/ASTInterpreter.java:620:in `blockNode&amp;amp;apos;
... 121 levels...
       from ruby.opt.hbase_minus_0_dot_2_dot_1.bin.hirbInvokermethod__23$RUBY$startOpt:-1:in `call&amp;amp;apos;
       from org/jruby/internal/runtime/methods/DynamicMethod.java:74:in `call&amp;amp;apos;
       from org/jruby/internal/runtime/methods/CompiledMethod.java:48:in `call&amp;amp;apos;
       from org/jruby/runtime/CallSite.java:123:in `cacheAndCall&amp;amp;apos;
       from org/jruby/runtime/CallSite.java:298:in `call&amp;amp;apos;
       from ruby/opt/hbase_minus_0_dot_2_dot_1/bin//opt/hbase/bin/../bin/hirb.rb:351:in `_file_&amp;amp;apos;
       from ruby/opt/hbase_minus_0_dot_2_dot_1/bin//opt/hbase/bin/../bin/hirb.rb:-1:in `_file_&amp;amp;apos;
       from ruby/opt/hbase_minus_0_dot_2_dot_1/bin//opt/hbase/bin/../bin/hirb.rb:-1:in `load&amp;amp;apos;
       from org/jruby/Ruby.java:512:in `runScript&amp;amp;apos;
       from org/jruby/Ruby.java:432:in `runNormally&amp;amp;apos;
       from org/jruby/Ruby.java:312:in `runFromMain&amp;amp;apos;
       from org/jruby/Main.java:144:in `run&amp;amp;apos;
       from org/jruby/Main.java:89:in `run&amp;amp;apos;
       from org/jruby/Main.java:80:in `main&amp;amp;apos;
       from /opt/hbase/bin/../bin/hirb.rb:254:in `disable&amp;amp;apos;
</description>
			
			
			<version>0.2.1</version>
			
			
			<fixedVersion>0.2.1, 0.18.0</fixedVersion>
			
			
			<type>Bug</type>
			
		
		</buginformation>
		
		
		<fixedFiles>
			
			
			<file type="M">org.apache.hadoop.hbase.util.migration.v5.HColumnDescriptor.java</file>
			
			
			<file type="M">org.apache.hadoop.hbase.client.RegionOfflineException.java</file>
			
			
			<file type="M">org.apache.hadoop.hbase.client.HBaseAdmin.java</file>
			
			
			<file type="M">org.apache.hadoop.hbase.TableNotFoundException.java</file>
			
			
			<file type="M">org.apache.hadoop.hbase.client.NoServerForRegionException.java</file>
			
		
		</fixedFiles>
		
	
	</bug>
	<bug fixdate="2008-09-07 22:17:18" id="871" opendate="2008-09-04 21:40:49" resolution="Fixed">
		
		
		<buginformation>
			
			
			<summary>Major compaction periodicity should be specifyable at the column family level, not cluster wide</summary>
			
			
			<description>jon gray has a table of ten rows and a couple of columns that is constantly being updated.  Has max versions of 2.  This table is growing fast because all versions written are kept until a major compaction.  The way this table is being used is different than that of others.  Would be good if he could have major compactions run more often than the default once a day.</description>
			
			
			<version>0.2.1</version>
			
			
			<fixedVersion>0.2.1, 0.18.0</fixedVersion>
			
			
			<type>Bug</type>
			
		
		</buginformation>
		
		
		<fixedFiles>
			
			
			<file type="M">org.apache.hadoop.hbase.regionserver.HStoreFile.java</file>
			
			
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
			
			
			<file type="M">org.apache.hadoop.hbase.HStoreKey.java</file>
			
			
			<file type="M">org.apache.hadoop.hbase.client.MetaScanner.java</file>
			
			
			<file type="M">org.apache.hadoop.hbase.regionserver.TestHStoreFile.java</file>
			
			
			<file type="M">org.apache.hadoop.hbase.regionserver.HStore.java</file>
			
			
			<file type="M">org.apache.hadoop.hbase.regionserver.StoreFileScanner.java</file>
			
			
			<file type="M">org.apache.hadoop.hbase.master.MetaRegion.java</file>
			
			
			<file type="M">org.apache.hadoop.hbase.regionserver.Memcache.java</file>
			
			
			<file type="M">org.apache.hadoop.hbase.regionserver.HStoreScanner.java</file>
			
			
			<file type="M">org.apache.hadoop.hbase.client.HConnectionManager.java</file>
			
			
			<file type="M">org.apache.hadoop.hbase.HConstants.java</file>
			
			
			<file type="M">org.apache.hadoop.hbase.HRegionInfo.java</file>
			
		
		</fixedFiles>
		
		
		<links>
			
			
			<link description="relates to" type="Reference">800</link>
			
		
		</links>
		
	
	</bug>
	<bug fixdate="2008-09-08 17:17:22" id="868" opendate="2008-09-04 17:08:45" resolution="Fixed">
		
		
		<buginformation>
			
			
			<summary>Incrementing binary rows cause strange behavior once table splits</summary>
			
			
			<description>We&amp;amp;apos;re now using incrementing binary row keys and to this point had only been doing small tests with them, never having actually had a table split.
I&amp;amp;apos;m still working through the logs but it seems that there&amp;amp;apos;s a problem somewhere with startKey and endKeys.
Binary in general is not well supported (inconsistent in display in the logs, very odd rendering in the web ui, hard to interpret in the shell, etc..)  Once we figure out these serious bugs we will spend some time trying to clean that up.  But right now this makes things even harder to debug.
The actual symptoms are that my import eventually started to throw (in the client and on the region server):
org.apache.hadoop.hbase.regionserver.WrongRegionException: org.apache.hadoop.hbase.regionserver.WrongRegionException: Requested row out of range for HRegion sources,,1220546297947, startKey=&amp;amp;apos;&amp;amp;apos;, getEndKey()=&amp;amp;apos;
&amp;amp;apos;, row=&amp;amp;apos;c&amp;amp;apos;
        at org.apache.hadoop.hbase.regionserver.HRegion.checkRow(HRegion.java:1775)
        at org.apache.hadoop.hbase.regionserver.HRegion.obtainRowLock(HRegion.java:1831)
        at org.apache.hadoop.hbase.regionserver.HRegion.batchUpdate(HRegion.java:1387)
        at org.apache.hadoop.hbase.regionserver.HRegionServer.batchUpdate(HRegionServer.java:1145)
        at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:616)
        at org.apache.hadoop.hbase.ipc.HbaseRPC$Server.call(HbaseRPC.java:473)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)
There are 3 regionservers, but this error only happens on one of them (while the other two always continue normally, allowing updates to this same table).
The regionserver that this happens on is special for two reasons, one it is hosting the META table.  And secondly it also hosts the first region in the table, startkey = &amp;amp;apos;&amp;amp;apos;.  I&amp;amp;apos;m unsure which is the cause, I have a clue leading to both.
After about 15 minutes, the regionserver sees:
2008-09-04 09:52:57,948 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Started memcache flush for region .META.,,1. Current region memcache size 24.5k
2008-09-04 09:52:58,003 DEBUG org.apache.hadoop.hbase.regionserver.HStore: Added /hbase/.META./1028785192/historian/mapfiles/8699673838203663799 with 106 entries, sequence id 25341510, data size 8.9k, file size 10.6k
2008-09-04 09:52:58,050 DEBUG org.apache.hadoop.hbase.regionserver.HStore: Added /hbase/.META./1028785192/info/mapfiles/1791564557665476834 with 96 entries, sequence id 25341510, data size 14.2k, file size 15.8k
2008-09-04 09:52:58,050 DEBUG org.apache.hadoop.hbase.regionserver.HRegion: Finished memcache flush for region .META.,,1 in 102ms, sequence id=25341510, compaction requested=true
2008-09-04 09:52:58,050 DEBUG org.apache.hadoop.hbase.regionserver.CompactSplitThread: Compaction requested for region: .META.,,1
2008-09-04 09:52:58,051 INFO org.apache.hadoop.hbase.regionserver.HRegion: starting compaction on region .META.,,1
2008-09-04 09:52:58,055 DEBUG org.apache.hadoop.hbase.regionserver.HStore: Compaction size of 1028785192/historian: 41.9k; Skipped 1 files , size: 21957
2008-09-04 09:52:58,088 DEBUG org.apache.hadoop.hbase.regionserver.HStore: started compaction of 2 files into /hbase/.META./compaction.dir/1028785192/historian/mapfiles/6948796056606699674
2008-09-04 09:52:58,128 DEBUG org.apache.hadoop.hbase.regionserver.HStore: moving /hbase/.META./compaction.dir/1028785192/historian/mapfiles/6948796056606699674 to /hbase/.META./1028785192/historian/mapfiles/75733875840914142
2008-09-04 09:52:58,175 DEBUG org.apache.hadoop.hbase.regionserver.HStore: Completed compaction of 1028785192/historian store size is 41.1k; time since last major compaction: 5426 seconds
2008-09-04 09:52:58,179 DEBUG org.apache.hadoop.hbase.regionserver.HStore: Compaction size of 1028785192/info: 61.9k; Skipped 0 files , size: 0
2008-09-04 09:52:58,192 DEBUG org.apache.hadoop.hbase.regionserver.HStore: started compaction of 3 files into /hbase/.META./compaction.dir/1028785192/info/mapfiles/7781013568996125923
2008-09-04 09:52:58,260 DEBUG org.apache.hadoop.hbase.regionserver.HStore: moving /hbase/.META./compaction.dir/1028785192/info/mapfiles/7781013568996125923 to /hbase/.META./1028785192/info/mapfiles/2187291308709057119
2008-09-04 09:52:58,290 DEBUG org.apache.hadoop.hbase.regionserver.HStore: Completed compaction of 1028785192/info store size is 61.0k; time since last major compaction: 32534 seconds
2008-09-04 09:52:58,296 INFO org.apache.hadoop.hbase.regionserver.HRegion: compaction completed on region .META.,,1 in 0sec
2008-09-04 09:53:09,620 INFO org.apache.hadoop.hbase.regionserver.HRegionServer: Scanner -2085474968086468199 lease expired
2008-09-04 09:54:35,449 INFO org.apache.hadoop.hbase.regionserver.LogRoller: Rolling hlog. Number of entries: 30009
Following this, insertion continues normally.  This leads me to believe there&amp;amp;apos;s an issue with the META table memcache, but oddly the other regions of this table on other regionservers continue on fine.
As for the hosting the first region of the table on this region server, it seems to be consistent that I get the row out of range errors when looking for a region with startkey = &amp;amp;apos;&amp;amp;apos;, although there are 5 other regions on this RS.
Will attach full logs from master and three RS.  Also a couple screenshots showing weird behavior in listing the regions in the table.</description>
			
			
			<version>0.2.1</version>
			
			
			<fixedVersion>0.2.1, 0.18.0</fixedVersion>
			
			
			<type>Bug</type>
			
		
		</buginformation>
		
		
		<fixedFiles>
			
			
			<file type="M">org.apache.hadoop.hbase.regionserver.HStoreFile.java</file>
			
			
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
			
			
			<file type="M">org.apache.hadoop.hbase.HStoreKey.java</file>
			
			
			<file type="M">org.apache.hadoop.hbase.client.MetaScanner.java</file>
			
			
			<file type="M">org.apache.hadoop.hbase.regionserver.TestHStoreFile.java</file>
			
			
			<file type="M">org.apache.hadoop.hbase.regionserver.HStore.java</file>
			
			
			<file type="M">org.apache.hadoop.hbase.regionserver.StoreFileScanner.java</file>
			
			
			<file type="M">org.apache.hadoop.hbase.master.MetaRegion.java</file>
			
			
			<file type="M">org.apache.hadoop.hbase.regionserver.Memcache.java</file>
			
			
			<file type="M">org.apache.hadoop.hbase.regionserver.HStoreScanner.java</file>
			
			
			<file type="M">org.apache.hadoop.hbase.client.HConnectionManager.java</file>
			
			
			<file type="M">org.apache.hadoop.hbase.HConstants.java</file>
			
			
			<file type="M">org.apache.hadoop.hbase.HRegionInfo.java</file>
			
		
		</fixedFiles>
		
		
		<links>
			
			
			<link description="is part of" type="Incorporates">877</link>
			
		
		</links>
		
	
	</bug>
	<bug fixdate="2008-09-10 19:39:51" id="877" opendate="2008-09-08 02:35:46" resolution="Fixed">
		
		
		<buginformation>
			
			
			<summary>HCM is unable to find table with multiple regions which contains binary</summary>
			
			
			<description>HCM can not find the table with exception:
org.apache.hadoop.hbase.TableNotFoundException: items
        at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.locateRegionInMeta(HConnectionManager.java:508)
        at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.locateRegion(HConnectionManager.java:460)
        at org.apache.hadoop.hbase.client.HConnectionManager$TableServers.locateRegion(HConnectionManager.java:420)
        at org.apache.hadoop.hbase.client.HTable.&amp;lt;init&amp;gt;(HTable.java:130)
        at HBaseRef.&amp;lt;init&amp;gt;(HBaseRef.java:29)
        at Import.&amp;lt;init&amp;gt;(Import.java:20)
        at Import.main(Import.java:26)
I have a fix already for this.  But the problem re-appeared after some time.  I have no recreated it yet, but will post results in the morning.</description>
			
			
			<version>0.2.1</version>
			
			
			<fixedVersion>0.2.1, 0.18.0</fixedVersion>
			
			
			<type>Bug</type>
			
		
		</buginformation>
		
		
		<fixedFiles>
			
			
			<file type="M">org.apache.hadoop.hbase.regionserver.BeforeThisStoreKey.java</file>
			
			
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegion.java</file>
			
			
			<file type="M">org.apache.hadoop.hbase.HTableDescriptor.java</file>
			
			
			<file type="M">org.apache.hadoop.hbase.HStoreKey.java</file>
			
			
			<file type="M">org.apache.hadoop.hbase.HMerge.java</file>
			
			
			<file type="M">org.apache.hadoop.hbase.regionserver.HStoreFile.java</file>
			
			
			<file type="M">org.apache.hadoop.hbase.regionserver.HStore.java</file>
			
			
			<file type="M">org.apache.hadoop.hbase.regionserver.Memcache.java</file>
			
			
			<file type="M">org.apache.hadoop.hbase.regionserver.TestHStoreFile.java</file>
			
		
		</fixedFiles>
		
		
		<links>
			
			
			<link description="incorporates" type="Incorporates">868</link>
			
		
		</links>
		
	
	</bug>
	<bug fixdate="2008-09-22 21:48:24" id="891" opendate="2008-09-19 17:14:00" resolution="Fixed">
		
		
		<buginformation>
			
			
			<summary>HRS.validateValuesLength throws IOE, gets caught in the retries</summary>
			
			
			<description>When HRS.validateValuesLength throws a IOE, it gets caught in the retries because it does not use a DoNotRetryIOException.</description>
			
			
			<version>0.2.1</version>
			
			
			<fixedVersion>0.2.2, 0.18.1, 0.19.0</fixedVersion>
			
			
			<type>Bug</type>
			
		
		</buginformation>
		
		
		<fixedFiles>
			
			
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
			
		
		</fixedFiles>
		
	
	</bug>
	<bug fixdate="2008-11-11 23:10:11" id="994" opendate="2008-11-11 19:38:11" resolution="Fixed">
		
		
		<buginformation>
			
			
			<summary>IPC interfaces with different versions can cause problems</summary>
			
			
			<description>This morning we ran into a situation in which some 0.2.x region servers started up and joined a 0.18.1 cluster. 
This &amp;amp;apos;sort of&amp;amp;apos; worked in that the hrs could communicate with the master, but clients could not communicate with the 0.2 region servers because the api version changed (the master wouldn&amp;amp;apos;t have liked it if it had deployed root or meta there).
Suggestion is that we have a single api version that gets bumped when any of the interfaces changes.</description>
			
			
			<version>0.2.1</version>
			
			
			<fixedVersion>0.19.0</fixedVersion>
			
			
			<type>Bug</type>
			
		
		</buginformation>
		
		
		<fixedFiles>
			
			
			<file type="M">org.apache.hadoop.hbase.ipc.TransactionalRegionInterface.java</file>
			
			
			<file type="M">org.apache.hadoop.hbase.ipc.HRegionInterface.java</file>
			
			
			<file type="M">org.apache.hadoop.hbase.ipc.HMasterInterface.java</file>
			
			
			<file type="M">org.apache.hadoop.hbase.ipc.HMasterRegionInterface.java</file>
			
			
			<file type="M">org.apache.hadoop.hbase.master.HMaster.java</file>
			
			
			<file type="M">org.apache.hadoop.hbase.client.HConnectionManager.java</file>
			
			
			<file type="M">org.apache.hadoop.hbase.regionserver.transactional.TransactionalRegionServer.java</file>
			
			
			<file type="M">org.apache.hadoop.hbase.regionserver.HRegionServer.java</file>
			
		
		</fixedFiles>
		
	
	</bug>
</bugrepository>
